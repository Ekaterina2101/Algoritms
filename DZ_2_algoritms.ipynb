{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[   1,    1,  500,    1],\n",
    "              [   1,    1,  700,    1],\n",
    "              [   1,    2,  750,    2],\n",
    "              [   1,    5,  600,    1],\n",
    "              [   1,    3, 1450,    2],\n",
    "              [   1,    0,  800,    1],\n",
    "              [   1,    5, 1500,    3],\n",
    "              [   1,   10, 2000,    3],\n",
    "              [   1,    1,  450,    1],\n",
    "              [   1,    2, 1000,    2]])\n",
    "\n",
    "y = [45, 55, 50, 55, 60, 35, 75, 80, 50, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.70710678, -0.97958969, -0.89625816],\n",
       "       [ 1.        , -0.70710678, -0.56713087, -0.89625816],\n",
       "       [ 1.        , -0.35355339, -0.46401617,  0.38411064],\n",
       "       [ 1.        ,  0.70710678, -0.77336028, -0.89625816],\n",
       "       [ 1.        ,  0.        ,  0.97958969,  0.38411064],\n",
       "       [ 1.        , -1.06066017, -0.36090146, -0.89625816],\n",
       "       [ 1.        ,  0.70710678,  1.08270439,  1.66447944],\n",
       "       [ 1.        ,  2.47487373,  2.11385144,  1.66447944],\n",
       "       [ 1.        , -0.70710678, -1.08270439, -0.89625816],\n",
       "       [ 1.        , -0.35355339,  0.05155735,  0.38411064]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standard_scale(X):\n",
    "    mean = X.mean()\n",
    "    std = X.std()\n",
    "    return (X - mean) / std\n",
    "X_st = X.copy().astype(np.float64)\n",
    "X_st[:, 1] = standard_scale(X_st[:, 1])\n",
    "X_st[:, 2] = standard_scale(X_st[:, 2])\n",
    "X_st[:, 3] = standard_scale(X_st[:, 3])\n",
    "\n",
    "X_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.99666938, -0.36654775, -1.97775417, -0.84934938])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_mse(y, y_pred):\n",
    "    err = np.mean((y - y_pred)**2)\n",
    "    return err\n",
    "\n",
    "W = np.random.randn(X.shape[1])\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# стохастический градиентный спуск\n",
    "def stohastic_gradient_descent(X, y, iterations, batch_size, eta=1e-4):\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    n_batch = n // batch_size    \n",
    "    if n % batch_size != 0:\n",
    "        n_batch += 1\n",
    "    print(f'amount of batches is {n_batch}')\n",
    "        \n",
    "    for i in range(0, iterations):\n",
    "        \n",
    "        for b in range(n_batch):\n",
    "            start = batch_size * b\n",
    "            end = batch_size * (b + 1)\n",
    "            \n",
    "#             print(b, start, end)\n",
    "            \n",
    "            X_tmp = X[start : end, ]\n",
    "            y_tmp = y[start : end]\n",
    "\n",
    "            err = calc_mse(y, np.dot(X, W))\n",
    "            \n",
    "            y_pred_tmp = np.dot(X_tmp, W)\n",
    "            dQ = 2/len(y_tmp) * X_tmp.T @ (y_pred_tmp - y_tmp) # градиент функции ошибки\n",
    "            W -= (eta * dQ)\n",
    "        \n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(f'Iter: {i}, weights: {W}, error {err}')\n",
    "    \n",
    "    print(f'Final MSE: {calc_mse(y, np.dot(X, W))}')\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of batches is 3\n",
      "Iter: 0, weights: [ 3.0986442   0.65191905 -0.55350375  0.53288255], error 3089.8665795997254\n",
      "Iter: 500, weights: [57.05966446  6.07559376 -0.76217876  6.94902162], error 25.238263236871205\n",
      "Iter: 1000, weights: [57.05298076  6.12290095 -0.96161828  7.11162657], error 25.264135938665415\n",
      "Iter: 1500, weights: [57.05250522  6.12619777 -0.97571944  7.12316817], error 25.26650885713548\n",
      "Iter: 2000, weights: [57.05247156  6.1264311  -0.9767175   7.12398508], error 25.266679485288908\n",
      "Iter: 2500, weights: [57.05246918  6.12644762 -0.97678814  7.1240429 ], error 25.266691575552\n",
      "Iter: 3000, weights: [57.05246901  6.12644879 -0.97679314  7.12404699], error 25.266692431354393\n",
      "Iter: 3500, weights: [57.052469    6.12644887 -0.9767935   7.12404728], error 25.26669249192746\n",
      "Iter: 4000, weights: [57.052469    6.12644888 -0.97679352  7.1240473 ], error 25.26669249621478\n",
      "Iter: 4500, weights: [57.052469    6.12644888 -0.97679352  7.1240473 ], error 25.266692496518196\n",
      "Final MSE: 25.350670220452812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([57.052469  ,  6.12644888, -0.97679353,  7.1240473 ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stohastic_gradient_descent(X_st, y, iterations=5000, batch_size=4, eta=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_reg_l2(X, y, iterations, eta=1e-4, reg=1e-8):\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for i in range(0, iterations):\n",
    "        y_pred = np.dot(X, W)\n",
    "        err = calc_mse(y, y_pred)\n",
    "        \n",
    "        dQ = 2/n * X.T @ (y_pred - y) # градиент функции ошибки\n",
    "        dReg = reg * W # градиент регуляризации\n",
    "        \n",
    "        W -= eta * (dQ + dReg)\n",
    "        \n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(f'Iter: {i}, weights: {W}, error {err}')\n",
    "    \n",
    "    print(f'Final MSE: {calc_mse(y, np.dot(X, W))}')\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, weights: [ 0.91726659  0.2429124  -0.24997404  0.51140422], error 3379.910235034253\n",
      "Iter: 500, weights: [56.49489619  5.95006067  0.99702636  5.52339786], error 25.219532016063134\n",
      "Iter: 1000, weights: [56.49717505  6.19949201  0.12430239  6.1783235 ], error 24.94525715622309\n",
      "Iter: 1500, weights: [56.49717514  6.26656455 -0.18255095  6.4282528 ], error 24.90996333313266\n",
      "Iter: 2000, weights: [56.49717514  6.28953561 -0.29258083  6.51889964], error 24.90534630692182\n",
      "Iter: 2500, weights: [56.49717514  6.29774044 -0.33214669  6.5515483 ], error 24.904730762770733\n",
      "Iter: 3000, weights: [56.49717514  6.30068918 -0.34638001  6.56329594], error 24.9046446268955\n",
      "Iter: 3500, weights: [56.49717514  6.30174987 -0.35150055  6.56752238], error 24.904631151810424\n",
      "Iter: 4000, weights: [56.49717514  6.30213146 -0.35334272  6.56904289], error 24.904628570703952\n",
      "Iter: 4500, weights: [56.49717514  6.30226874 -0.35400547  6.56958992], error 24.90462793549744\n",
      "Final MSE: 24.904627744945806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([56.49717514,  6.30231807, -0.35424362,  6.56978649])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent_reg_l2(X_st, y, iterations=5000, eta=1e-2, reg=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, weights: [-0.67618301  0.64864984  0.1975439   1.17844917], error 3534.504940277226\n",
      "Iter: 500, weights: [56.49737204  5.95318477  0.9590995   5.55942234], error 25.201551533180098\n",
      "Iter: 1000, weights: [56.49971741  6.20266185  0.10918732  6.19097355], error 24.94271452611036\n",
      "Iter: 1500, weights: [56.4997175   6.26820552 -0.189099    6.43359758], error 24.90956061255453\n",
      "Iter: 2000, weights: [56.4997175   6.29055553 -0.29606954  6.52170721], error 24.90526185908511\n",
      "Iter: 2500, weights: [56.4997175   6.29853634 -0.33455081  6.55346003], error 24.904703231638354\n",
      "Iter: 3000, weights: [56.4997175   6.30140557 -0.3484001   6.56489067], error 24.904630234903944\n",
      "Iter: 3500, weights: [56.4997175   6.30243811 -0.35338474  6.56900493], error 24.904620552011785\n",
      "Iter: 4000, weights: [56.4997175   6.30280974 -0.35517882  6.57048575], error 24.904619216106774\n",
      "Iter: 4500, weights: [56.4997175   6.3029435  -0.35582456  6.57101874], error 24.90461901370055\n",
      "Final MSE: 24.904618976917344\n",
      "Iter: 0, weights: [-0.70710604  1.97188833  0.02287799  0.57780312], error 3527.72314797389\n",
      "Iter: 500, weights: [56.49699361  6.01113989  0.95013492  5.51334031], error 25.203236114676635\n",
      "Iter: 1000, weights: [56.49934007  6.20492306  0.11192546  6.18598728], error 24.943317415111117\n",
      "Iter: 1500, weights: [56.49934017  6.26800912 -0.18765476  6.43227625], error 24.909649599548043\n",
      "Iter: 2000, weights: [56.49934017  6.2903732  -0.29536654  6.52113058], error 24.905277337875003\n",
      "Iter: 2500, weights: [56.49934017  6.2984046  -0.33412647  6.5531202 ], error 24.904706895520924\n",
      "Iter: 3000, weights: [56.49934017  6.30129421 -0.34807587  6.56463382], error 24.904631526803364\n",
      "Iter: 3500, weights: [56.49934017  6.30233413 -0.35309624  6.56877759], error 24.90462123157237\n",
      "Iter: 4000, weights: [56.49934017  6.30270839 -0.35490307  6.57026893], error 24.90461970626469\n",
      "Iter: 4500, weights: [56.49934017  6.30284309 -0.35555334  6.57080566], error 24.904619439669712\n",
      "Final MSE: 24.90461938029607\n",
      "Iter: 0, weights: [2.4081327  0.54974729 1.35591149 2.04524746], error 3143.2743759381656\n",
      "Iter: 500, weights: [56.49624045  5.89846206  1.06693119  5.50117187], error 25.2505403412189\n",
      "Iter: 1000, weights: [56.49845875  6.19342383  0.14511601  6.16292467], error 24.948750967968586\n",
      "Iter: 1500, weights: [56.49845884  6.26522    -0.17580486  6.42274094], error 24.91037805197908\n",
      "Iter: 2000, weights: [56.49845884  6.28929855 -0.2907342   6.51734354], error 24.90538288351892\n",
      "Iter: 2500, weights: [56.49845884  6.29787318 -0.33206251  6.55144239], error 24.904725836922676\n",
      "Iter: 3000, weights: [56.49845884  6.30095411 -0.34693278  6.56371553], error 24.904637071488086\n",
      "Iter: 3500, weights: [56.49845884  6.30206252 -0.35228367  6.56813209], error 24.90462425094524\n",
      "Iter: 4000, weights: [56.49845884  6.30246137 -0.35420915  6.56972136], error 24.904622113493325\n",
      "Iter: 4500, weights: [56.49845884  6.30260489 -0.35490202  6.57029325], error 24.90462166494716\n",
      "Final MSE: 24.9046215450546\n",
      "Iter: 0, weights: [-0.57383799  0.59235458  1.05780162  0.92976735], error 3512.1248995871492\n",
      "Iter: 500, weights: [56.49406068  5.90036716  1.18637936  5.37701955], error 25.31379337564624\n",
      "Iter: 1000, weights: [56.49640031  6.18492561  0.19162588  6.12328252], error 24.957439510605376\n",
      "Iter: 1500, weights: [56.4964004   6.26137355 -0.15805955  6.40808569], error 24.91157790665917\n",
      "Iter: 2000, weights: [56.4964004   6.28754781 -0.28342934  6.51136951], error 24.905572468786183\n",
      "Iter: 2500, weights: [56.4964004   6.29689525 -0.32850506  6.54856471], error 24.904769321864116\n",
      "Iter: 3000, weights: [56.4964004   6.30025417 -0.34471824  6.56194646], error 24.904656013919265\n",
      "Iter: 3500, weights: [56.4964004   6.30146224 -0.35055026  6.56676014], error 24.904637976130015\n",
      "Iter: 4000, weights: [56.4964004   6.30189679 -0.3526481   6.56849168], error 24.90463442757394\n",
      "Iter: 4500, weights: [56.4964004   6.3020531  -0.35340272  6.56911454], error 24.904633531510967\n",
      "Final MSE: 24.90463325840677\n",
      "Iter: 0, weights: [ 1.20476019 -0.89256911  1.23736956 -0.60119635], error 3366.029916636276\n",
      "Iter: 500, weights: [56.48932841  5.80451911  1.55835876  5.08749994], error 25.535190940194546\n",
      "Iter: 1000, weights: [56.49159297  6.15577579  0.32515263  6.01409173], error 24.986375322020372\n",
      "Iter: 1500, weights: [56.49159306  6.25042344 -0.10814322  6.36706727], error 24.915572524239572\n",
      "Iter: 2000, weights: [56.49159306  6.28282602 -0.26336493  6.49494796], error 24.90621905842749\n",
      "Iter: 2500, weights: [56.49159306  6.29438921 -0.31912652  6.54096104], error 24.904935494729745\n",
      "Iter: 3000, weights: [56.49159306  6.29854086 -0.3391662   6.55750104], error 24.90474260449232\n",
      "Iter: 3500, weights: [56.49159306  6.30003277 -0.34636849  6.56344574], error 24.90470795207883\n",
      "Iter: 4000, weights: [56.49159306  6.30056896 -0.34895703  6.5655823 ], error 24.904699976638152\n",
      "Iter: 4500, weights: [56.49159306  6.30076167 -0.34988737  6.56635019], error 24.904697688760855\n",
      "Final MSE: 24.90469694121675\n",
      "Iter: 0, weights: [0.95592162 0.1779014  0.83939619 0.49273797], error 3354.0408443759816\n",
      "Iter: 500, weights: [56.47809786  5.88598388  1.23748784  5.33711999], error 25.341992322747945\n",
      "Iter: 1000, weights: [56.48036753  6.17801534  0.21550627  6.10411037], error 24.96252766330103\n",
      "Iter: 1500, weights: [56.48036763  6.2563233  -0.14276278  6.39592026], error 24.91306626129108\n",
      "Iter: 2000, weights: [56.48036763  6.28306339 -0.27084682  6.50144098], error 24.906300495000224\n",
      "Iter: 2500, weights: [56.48036763  6.29258605 -0.31676769  6.53933363], error 24.90528518525999\n",
      "Iter: 3000, weights: [56.48036763  6.29599822 -0.33323795  6.55292755], error 24.90510259615455\n",
      "Iter: 3500, weights: [56.48036763  6.29722196 -0.33914562  6.55780367], error 24.905060466239036\n",
      "Iter: 4000, weights: [56.48036763  6.29766089 -0.34126463  6.55955269], error 24.90504836048276\n",
      "Iter: 4500, weights: [56.48036763  6.29781833 -0.3420247   6.56018005], error 24.90504440499249\n",
      "Final MSE: 24.905043035952854\n",
      "Iter: 0, weights: [ 0.25194575 -0.03085804 -0.88668473  0.13016363], error 3488.4042283404706\n",
      "Iter: 500, weights: [56.4518789   5.96089785  0.94950443  5.55810014], error 25.20064352032728\n",
      "Iter: 1000, weights: [56.45416543  6.19488341  0.12386062  6.17959099], error 24.947319674614672\n",
      "Iter: 1500, weights: [56.45416552  6.25779637 -0.16443602  6.41450455], error 24.913245374822804\n",
      "Iter: 2000, weights: [56.45416552  6.27921108 -0.26703634  6.49903567], error 24.90814950372657\n",
      "Iter: 2500, weights: [56.45416552  6.28680355 -0.30365054  6.52924896], error 24.90723072468106\n",
      "Iter: 3000, weights: [56.45416552  6.28951155 -0.31672189  6.54003756], error 24.90701747530914\n",
      "Iter: 3500, weights: [56.45416552  6.29047824 -0.32138864  6.54388945], error 24.906955969539702\n",
      "Iter: 4000, weights: [56.45416552  6.29082337 -0.32305479  6.54526467], error 24.906935875188328\n",
      "Iter: 4500, weights: [56.45416552  6.29094658 -0.32364964  6.54575566], error 24.906928938692637\n",
      "Final MSE: 24.90692649248725\n",
      "Iter: 0, weights: [ 2.11340583 -0.24453372  0.13911707 -0.80392512], error 3277.724054831576\n",
      "Iter: 500, weights: [56.39087521  5.87561871  1.33965978  5.23523498], error 25.41490464091888\n",
      "Iter: 1000, weights: [56.39305921  6.1546334   0.28456529  6.04849402], error 24.98854175363379\n",
      "Iter: 1500, weights: [56.3930593   6.23357883 -0.08190395  6.34808332], error 24.929468285457613\n",
      "Iter: 2000, weights: [56.3930593   6.26047611 -0.21101958  6.45450933], error 24.919895681897348\n",
      "Iter: 2500, weights: [56.3930593   6.26992594 -0.25660336  6.4921266 ], error 24.91792228710777\n",
      "Iter: 3000, weights: [56.3930593   6.27326082 -0.27270123  6.50541332], error 24.917400849188866\n",
      "Iter: 3500, weights: [56.3930593   6.27443847 -0.27838642  6.51010581], error 24.917238582615962\n",
      "Iter: 4000, weights: [56.3930593   6.27485437 -0.28039424  6.51176305], error 24.917184005428506\n",
      "Iter: 4500, weights: [56.3930593   6.27500125 -0.28110333  6.51234833], error 24.917165071091212\n",
      "Final MSE: 24.917158426588664\n",
      "Iter: 0, weights: [ 1.8275671  -1.03815062  0.54265886  0.08626928], error 3297.925538302084\n",
      "Iter: 500, weights: [56.24871223  5.81519369  1.34352135  5.27699623], error 25.46584261758289\n",
      "Iter: 1000, weights: [56.25084613  6.12662984  0.33026074  6.01657855], error 25.050290077429565\n",
      "Iter: 1500, weights: [ 5.62508462e+01  6.20177874e+00 -8.54176316e-03  6.29148888e+00], error 24.9886562997274\n",
      "Iter: 2000, weights: [56.25084622  6.22608353 -0.12470322  6.38713607], error 24.976769600579726\n",
      "Iter: 2500, weights: [56.25084622  6.23437519 -0.16467517  6.42011731], error 24.97378075858329\n",
      "Iter: 3000, weights: [56.25084622  6.23722636 -0.17843691  6.43147561], error 24.972882421702145\n",
      "Iter: 3500, weights: [56.25084622  6.23820788 -0.18317523  6.43538656], error 24.972588608520024\n",
      "Iter: 4000, weights: [56.25084622  6.23854582 -0.18480669  6.43673316], error 24.97248928134437\n",
      "Iter: 4500, weights: [56.25084622  6.23866218 -0.18536843  6.43719681], error 24.972455299315474\n",
      "Final MSE: 24.972443624623157\n",
      "Iter: 0, weights: [ 2.04426991  0.9885017  -1.50375633  1.25841961], error 3244.9613096946805\n",
      "Iter: 500, weights: [55.91946515  5.96753124  0.72966918  5.73205357], error 25.450894159741857\n",
      "Iter: 1000, weights: [55.92145388  6.10933436  0.24692072  6.09067755], error 25.306829190662334\n",
      "Iter: 1500, weights: [55.92145395  6.14290008  0.09418273  6.21490979], error 25.27842159327267\n",
      "Iter: 2000, weights: [5.59214540e+01 6.15321792e+00 4.48006965e-02 6.25558470e+00], error 25.27098801150961\n",
      "Iter: 2500, weights: [5.59214540e+01 6.15653951e+00 2.87849117e-02 6.26880012e+00], error 25.268762145980723\n",
      "Iter: 3000, weights: [5.59214540e+01 6.15761613e+00 2.35882932e-02 6.27308920e+00], error 25.2680594118053\n",
      "Iter: 3500, weights: [5.59214540e+01 6.15796542e+00 2.19020472e-02 6.27448101e+00], error 25.267833434283766\n",
      "Iter: 4000, weights: [5.59214540e+01 6.15807876e+00 2.13548739e-02 6.27493264e+00], error 25.267760322446552\n",
      "Iter: 4500, weights: [5.59214540e+01 6.15811554e+00 2.11773203e-02 6.27507919e+00], error 25.26773662095935\n",
      "Final MSE: 25.2677289324004\n",
      "Iter: 0, weights: [ 0.84027835  0.26746383 -1.26445031  1.20367758], error 3395.3829104731385\n",
      "Iter: 500, weights: [55.16516929  5.81524095  1.00540955  5.53112077], error 27.03066347938186\n",
      "Iter: 1000, weights: [55.16691079  5.95475254  0.5860836   5.82706246], error 26.856132965859366\n",
      "Iter: 1500, weights: [55.16691084  5.98051611  0.47190451  5.91929225], error 26.820328550563538\n",
      "Iter: 2000, weights: [55.16691084  5.98724706  0.43981891  5.94569473], error 26.81109492177486\n",
      "Iter: 2500, weights: [55.16691084  5.9891267   0.43076106  5.95316778], error 26.80855436202675\n",
      "Iter: 3000, weights: [55.16691084  5.98965685  0.42820233  5.95527961], error 26.807841955285216\n",
      "Iter: 3500, weights: [55.16691084  5.98980659  0.42747945  5.95587626], error 26.807641110791327\n",
      "Iter: 4000, weights: [55.16691084  5.98984889  0.42727523  5.95604483], error 26.807584402247862\n",
      "Iter: 4500, weights: [55.16691084  5.98986084  0.42721753  5.95609245], error 26.80756838374391\n",
      "Final MSE: 26.807563858442155\n",
      "Iter: 0, weights: [2.1136636  0.84171371 1.68087953 0.67266979], error 3189.2457350937802\n",
      "Iter: 500, weights: [53.48022372  5.49997949  1.75909704  4.9137246 ], error 34.90849932755424\n",
      "Iter: 1000, weights: [53.48140798  5.64556531  1.22711995  5.31909324], error 34.55105351387634\n",
      "Iter: 1500, weights: [53.48140801  5.66868216  1.12047293  5.40614135], error 34.492856097206904\n",
      "Iter: 2000, weights: [53.48140801  5.6732146   1.09873542  5.42405501], error 34.48149541153912\n",
      "Iter: 2500, weights: [53.48140801  5.67413542  1.09429416  5.42771997], error 34.479195150135254\n",
      "Iter: 3000, weights: [53.48140801  5.67432346  1.09338645  5.42846917], error 34.47872588614172\n",
      "Iter: 3500, weights: [53.48140801  5.6743619   1.09320092  5.4286223 ], error 34.47863000848214\n",
      "Iter: 4000, weights: [53.48140801  5.67436975  1.093163    5.4286536 ], error 34.47861041322382\n",
      "Iter: 4500, weights: [53.48140801  5.67437136  1.09315524  5.42866   ], error 34.478606408140195\n",
      "Final MSE: 34.47860558952901\n",
      "Iter: 0, weights: [ 1.72412352  0.73440636 -1.8951772  -0.69913445], error 3347.189688042533\n",
      "Iter: 500, weights: [49.91853115  5.15080921  1.99187493  4.67864962], error 69.64116954221035\n",
      "Iter: 1000, weights: [49.91904522  5.16588489  1.91088696  4.7471164 ], error 69.5667597817081\n",
      "Iter: 1500, weights: [49.91904523  5.16748016  1.90307424  4.75358693], error 69.56035052571539\n",
      "Iter: 2000, weights: [49.91904523  5.16763515  1.90232446  4.75420609], error 69.5597362634572\n",
      "Iter: 2500, weights: [49.91904523  5.16765004  1.90225256  4.75426545], error 69.55967736267021\n",
      "Iter: 3000, weights: [49.91904523  5.16765147  1.90224566  4.75427114], error 69.55967171478726\n",
      "Iter: 3500, weights: [49.91904523  5.16765161  1.902245    4.75427168], error 69.55967117322712\n",
      "Iter: 4000, weights: [49.91904523  5.16765162  1.90224494  4.75427173], error 69.55967112129846\n",
      "Iter: 4500, weights: [49.91904523  5.16765162  1.90224493  4.75427174], error 69.55967111631921\n",
      "Final MSE: 69.55967111584171\n",
      "Iter: 0, weights: [ 0.33599522 -0.65572749  1.14200255 -0.32757348], error 3457.41138766957\n",
      "Iter: 500, weights: [43.19814996  4.46670788  2.55700146  4.0489737 ], error 205.29212780891444\n",
      "Iter: 1000, weights: [43.19822516  4.47601164  2.52528818  4.07254403], error 205.25413455856943\n",
      "Iter: 1500, weights: [43.19822516  4.47612227  2.52478429  4.07295398], error 205.25358018390656\n",
      "Iter: 2000, weights: [43.19822516  4.47612398  2.52477611  4.07296071], error 205.2535712162528\n",
      "Iter: 2500, weights: [43.19822516  4.47612401  2.52477598  4.07296082], error 205.25357107027602\n",
      "Iter: 3000, weights: [43.19822516  4.47612401  2.52477598  4.07296083], error 205.25357106789775\n",
      "Iter: 3500, weights: [43.19822516  4.47612401  2.52477598  4.07296083], error 205.253571067859\n",
      "Iter: 4000, weights: [43.19822516  4.47612401  2.52477598  4.07296083], error 205.25357106785845\n",
      "Iter: 4500, weights: [43.19822516  4.47612401  2.52477598  4.07296083], error 205.25357106785845\n",
      "Final MSE: 205.25357106785845\n",
      "Iter: 0, weights: [1.73549195 0.5159922  1.00249031 0.50318155], error 3252.6269330717814\n",
      "Iter: 500, weights: [32.86364524  3.63323396  2.66345895  3.38170026], error 592.5328673124947\n",
      "Iter: 1000, weights: [32.86364602  3.63329352  2.6632534   3.38185373], error 592.5325538190882\n",
      "Iter: 1500, weights: [32.86364602  3.63329353  2.66325335  3.38185378], error 592.5325537532934\n",
      "Iter: 2000, weights: [32.86364602  3.63329353  2.66325335  3.38185378], error 592.5325537532769\n",
      "Iter: 2500, weights: [32.86364602  3.63329353  2.66325335  3.38185378], error 592.5325537532769\n",
      "Iter: 3000, weights: [32.86364602  3.63329353  2.66325335  3.38185378], error 592.5325537532769\n",
      "Iter: 3500, weights: [32.86364602  3.63329353  2.66325335  3.38185378], error 592.5325537532769\n",
      "Iter: 4000, weights: [32.86364602  3.63329353  2.66325335  3.38185378], error 592.5325537532769\n",
      "Iter: 4500, weights: [32.86364602  3.63329353  2.66325335  3.38185378], error 592.5325537532769\n",
      "Final MSE: 592.5325537532769\n",
      "Iter: 0, weights: [ 0.41317596 -1.48492175  0.68450369  0.29344526], error 3467.9475076824083\n",
      "Iter: 500, weights: [21.0828043   2.66922278  2.2627129   2.56328802], error 1302.88085462326\n",
      "Iter: 1000, weights: [21.0828043   2.66922278  2.26271289  2.56328803], error 1302.880854605999\n",
      "Iter: 1500, weights: [21.0828043   2.66922278  2.26271289  2.56328803], error 1302.880854605999\n",
      "Iter: 2000, weights: [21.0828043   2.66922278  2.26271289  2.56328803], error 1302.880854605999\n",
      "Iter: 2500, weights: [21.0828043   2.66922278  2.26271289  2.56328803], error 1302.880854605999\n",
      "Iter: 3000, weights: [21.0828043   2.66922278  2.26271289  2.56328803], error 1302.880854605999\n",
      "Iter: 3500, weights: [21.0828043   2.66922278  2.26271289  2.56328803], error 1302.880854605999\n",
      "Iter: 4000, weights: [21.0828043   2.66922278  2.26271289  2.56328803], error 1302.880854605999\n",
      "Iter: 4500, weights: [21.0828043   2.66922278  2.26271289  2.56328803], error 1302.880854605999\n",
      "Final MSE: 1302.880854605999\n",
      "Iter: 0, weights: [0.26546847 0.467236   1.40724856 0.71760653], error 3418.817023664279\n",
      "Iter: 500, weights: [11.47487747  1.69833146  1.54827038  1.66726316], error 2103.3644057838064\n",
      "Iter: 1000, weights: [11.47487747  1.69833146  1.54827038  1.66726316], error 2103.3644057838064\n",
      "Iter: 1500, weights: [11.47487747  1.69833146  1.54827038  1.66726316], error 2103.3644057838064\n",
      "Iter: 2000, weights: [11.47487747  1.69833146  1.54827038  1.66726316], error 2103.3644057838064\n",
      "Iter: 2500, weights: [11.47487747  1.69833146  1.54827038  1.66726316], error 2103.3644057838064\n",
      "Iter: 3000, weights: [11.47487747  1.69833146  1.54827038  1.66726316], error 2103.3644057838064\n",
      "Iter: 3500, weights: [11.47487747  1.69833146  1.54827038  1.66726316], error 2103.3644057838064\n",
      "Iter: 4000, weights: [11.47487747  1.69833146  1.54827038  1.66726316], error 2103.3644057838064\n",
      "Iter: 4500, weights: [11.47487747  1.69833146  1.54827038  1.66726316], error 2103.3644057838064\n",
      "Final MSE: 2103.3644057838064\n",
      "Iter: 0, weights: [-0.0357298   0.79657126  1.0181415  -0.55316595], error 3504.1578839838176\n",
      "Iter: 500, weights: [5.55834098 0.92772602 0.87476767 0.92156435], error 2703.5104592011803\n",
      "Iter: 1000, weights: [5.55834098 0.92772602 0.87476767 0.92156435], error 2703.5104592011803\n",
      "Iter: 1500, weights: [5.55834098 0.92772602 0.87476767 0.92156435], error 2703.5104592011803\n",
      "Iter: 2000, weights: [5.55834098 0.92772602 0.87476767 0.92156435], error 2703.5104592011803\n",
      "Iter: 2500, weights: [5.55834098 0.92772602 0.87476767 0.92156435], error 2703.5104592011803\n",
      "Iter: 3000, weights: [5.55834098 0.92772602 0.87476767 0.92156435], error 2703.5104592011803\n",
      "Iter: 3500, weights: [5.55834098 0.92772602 0.87476767 0.92156435], error 2703.5104592011803\n",
      "Iter: 4000, weights: [5.55834098 0.92772602 0.87476767 0.92156435], error 2703.5104592011803\n",
      "Iter: 4500, weights: [5.55834098 0.92772602 0.87476767 0.92156435], error 2703.5104592011803\n",
      "Final MSE: 2703.5104592011803\n",
      "Iter: 0, weights: [1.08651982 0.16443533 0.76214689 0.90066419], error 3317.703744396987\n",
      "Iter: 500, weights: [2.52157149 0.45155776 0.43221298 0.45106608], error 3046.9395671351926\n",
      "Iter: 1000, weights: [2.52157149 0.45155776 0.43221298 0.45106608], error 3046.9395671351926\n",
      "Iter: 1500, weights: [2.52157149 0.45155776 0.43221298 0.45106608], error 3046.9395671351926\n",
      "Iter: 2000, weights: [2.52157149 0.45155776 0.43221298 0.45106608], error 3046.9395671351926\n",
      "Iter: 2500, weights: [2.52157149 0.45155776 0.43221298 0.45106608], error 3046.9395671351926\n",
      "Iter: 3000, weights: [2.52157149 0.45155776 0.43221298 0.45106608], error 3046.9395671351926\n",
      "Iter: 3500, weights: [2.52157149 0.45155776 0.43221298 0.45106608], error 3046.9395671351926\n",
      "Iter: 4000, weights: [2.52157149 0.45155776 0.43221298 0.45106608], error 3046.9395671351926\n",
      "Iter: 4500, weights: [2.52157149 0.45155776 0.43221298 0.45106608], error 3046.9395671351926\n",
      "Final MSE: 3046.9395671351926\n",
      "Iter: 0, weights: [1.11884787 0.20654046 0.20254156 0.2102434 ], error 3280.451893954737\n",
      "Iter: 500, weights: [1.10784314 0.20547419 0.19795963 0.20576233], error 3215.845108956103\n",
      "Iter: 1000, weights: [1.10784314 0.20547419 0.19795963 0.20576233], error 3215.845108956103\n",
      "Iter: 1500, weights: [1.10784314 0.20547419 0.19795963 0.20576233], error 3215.845108956103\n",
      "Iter: 2000, weights: [1.10784314 0.20547419 0.19795963 0.20576233], error 3215.845108956103\n",
      "Iter: 2500, weights: [1.10784314 0.20547419 0.19795963 0.20576233], error 3215.845108956103\n",
      "Iter: 3000, weights: [1.10784314 0.20547419 0.19795963 0.20576233], error 3215.845108956103\n",
      "Iter: 3500, weights: [1.10784314 0.20547419 0.19795963 0.20576233], error 3215.845108956103\n",
      "Iter: 4000, weights: [1.10784314 0.20547419 0.19795963 0.20576233], error 3215.845108956103\n",
      "Iter: 4500, weights: [1.10784314 0.20547419 0.19795963 0.20576233], error 3215.845108956103\n",
      "Final MSE: 3215.845108956103\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=20\n",
    "coeffs1 = np.zeros((n, X.shape[1]))\n",
    "alpha_list = np.logspace(-5, 2, n)\n",
    "\n",
    "for i, val in enumerate(alpha_list):\n",
    "    reg1 = val\n",
    "  \n",
    "    coeffs1[i, :] = gradient_descent_reg_l2(X_st, y, iterations=5000, eta=1e-2, reg=reg1)\n",
    "\n",
    "for i in range(X.shape[1]):\n",
    "    plt.plot(alpha_list, coeffs1[:, i])\n",
    "\n",
    "plt.title('Убывание абсолютных значений весов признаков\\n при увеличении коэффициента регуляризации alpha (Ridge)')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Вес признака');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Вывод: при увеличение alfa уменьшаются веса, но увеличивается ошибка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Задание 2 (Cылка на вычисление производной не открылась, но по логике так:) В итогах разницы особой не увидела, чуть меньше ошибка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_reg_l1(X, y, iterations, eta=1e-4, reg=1e-8):\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for i in range(0, iterations):\n",
    "        y_pred = np.dot(X, W)\n",
    "        err = calc_mse(y, y_pred)\n",
    "        \n",
    "        dQ = 2/n * X.T @ (y_pred - y) # градиент функции ошибки\n",
    "        dReg = reg * np.sign(W) # градиент регуляризации\n",
    "        \n",
    "        W -= eta * (dQ + dReg)\n",
    "        \n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(f'Iter: {i}, weights: {W}, error {err}')\n",
    "    \n",
    "    print(f'Final MSE: {calc_mse(y, np.dot(X, W))}')\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, weights: [ 1.09547752  0.68713542 -0.06389205 -0.77270614], error 3375.320061608966\n",
      "Iter: 500, weights: [56.49767709  5.94143341  1.22446574  5.29918079], error 25.340483920061057\n",
      "Iter: 1000, weights: [56.49994991  6.18418677  0.20907552  6.10638168], error 24.961012910175832\n",
      "Iter: 1500, weights: [56.49995     6.26075991 -0.15276656  6.40353814], error 24.911942838679245\n",
      "Iter: 2000, weights: [56.49995     6.28775168 -0.28272357  6.51073466], error 24.90557733440321\n",
      "Iter: 2500, weights: [56.49995     6.29744316 -0.32949298  6.54933428], error 24.904746536960623\n",
      "Iter: 3000, weights: [56.49995     6.3009303  -0.34632684  6.56322866], error 24.904636706132212\n",
      "Iter: 3500, weights: [56.49995     6.30218541 -0.35238603  6.56822986], error 24.904621686802873\n",
      "Iter: 4000, weights: [56.49995     6.30263717 -0.35456698  6.57003001], error 24.90461945662055\n",
      "Iter: 4500, weights: [56.49995     6.30279978 -0.355352    6.57067796], error 24.904619065348054\n",
      "Final MSE: 24.904618977821116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([56.49995   ,  6.30285824, -0.35563423,  6.57091091])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent_reg_l1(X_st, y, iterations=5000, eta=1e-2, reg=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3:Можно ли к одному и тому же признаку применить сразу и нормализацию, и стандартизацию . Да можно (можно то, что не нельзя :)), но по факту будет выполненно то, что сделано последним. И смысл применения обоих методов от этого теряется."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
